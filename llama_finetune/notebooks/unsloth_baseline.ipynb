{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1GIQApjroeDaxeCWcKpQEazPhr-5ECQEb","timestamp":1746559674239}],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyMLj/lt0p4mi3vgcYd50UY5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"fcde6dbd522b4bcc8704e5728ff81522":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cbe01edf4e1f429a9ebeade6f5ff4d95","IPY_MODEL_20b14df9de3e48f0b299abb3be6b334b","IPY_MODEL_a31e91c2910748cf83a935f81c63fd54"],"layout":"IPY_MODEL_ea7340b323ae48f0b7ce2471844dce88"}},"cbe01edf4e1f429a9ebeade6f5ff4d95":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b9bf6fca43f2438195627702f8a22de6","placeholder":"​","style":"IPY_MODEL_49f45aedb1054b70b29ef4a0471ab1ab","value":"Unsloth: Tokenizing [&quot;text&quot;] (num_proc=2): 100%"}},"20b14df9de3e48f0b299abb3be6b334b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_01096f83b3dc4803b841987a16701fcf","max":227699,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d8022a63be6c4ab6a65b2d18dae3f284","value":227699}},"a31e91c2910748cf83a935f81c63fd54":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_12ee42d297604824aaccc6f1a38a082c","placeholder":"​","style":"IPY_MODEL_4e789055e9bb40f387668acd8348db06","value":" 227699/227699 [00:21&lt;00:00, 10776.80 examples/s]"}},"ea7340b323ae48f0b7ce2471844dce88":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b9bf6fca43f2438195627702f8a22de6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49f45aedb1054b70b29ef4a0471ab1ab":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"01096f83b3dc4803b841987a16701fcf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8022a63be6c4ab6a65b2d18dae3f284":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"12ee42d297604824aaccc6f1a38a082c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e789055e9bb40f387668acd8348db06":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["%%capture\n","import os\n","if \"COLAB_\" not in \"\".join(os.environ.keys()):\n","    !pip install unsloth\n","else:\n","    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n","    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl==0.15.2 triton cut_cross_entropy unsloth_zoo\n","    !pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n","    !pip install --no-deps unsloth"],"metadata":{"id":"_SXN5DQWJ8Ro","executionInfo":{"status":"ok","timestamp":1746561421249,"user_tz":240,"elapsed":4724,"user":{"displayName":"Tanmay Bankar","userId":"15426054109741671763"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["from unsloth import FastLanguageModel\n","import torch\n","max_seq_length = 64 # Choose any! We auto support RoPE Scaling internally!\n","dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n","load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n","\n","# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n","fourbit_models = [\n","    \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",      # Llama-3.1 2x faster\n","    \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n","    \"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n","    \"unsloth/Meta-Llama-3.1-405B-bnb-4bit\",    # 4bit for 405b!\n","    \"unsloth/Mistral-Small-Instruct-2409\",     # Mistral 22b 2x faster!\n","    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n","    \"unsloth/Phi-3.5-mini-instruct\",           # Phi-3.5 2x faster!\n","    \"unsloth/Phi-3-medium-4k-instruct\",\n","    \"unsloth/gemma-2-9b-bnb-4bit\",\n","    \"unsloth/gemma-2-27b-bnb-4bit\",            # Gemma 2x faster!\n","\n","    \"unsloth/Llama-3.2-1B-bnb-4bit\",           # NEW! Llama 3.2 models\n","    \"unsloth/Llama-3.2-1B-Instruct-bnb-4bit\",\n","    \"unsloth/Llama-3.2-3B-bnb-4bit\",\n","    \"unsloth/Llama-3.2-3B-Instruct-bnb-4bit\",\n","\n","    \"unsloth/Llama-3.3-70B-Instruct-bnb-4bit\" # NEW! Llama 3.3 70B!\n","] # More models at https://huggingface.co/unsloth\n","\n","model, tokenizer = FastLanguageModel.from_pretrained(\n","    # model_name = \"unsloth/Llama-3.2-3B-Instruct\", # or choose \"unsloth/Llama-3.2-1B-Instruct\"\n","    model_name = \"unsloth/Llama-3.2-1B-bnb-4bit\",\n","    max_seq_length = max_seq_length,\n","    dtype = dtype,\n","    load_in_4bit = load_in_4bit,\n","    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CrLeXO4lg9yk","executionInfo":{"status":"ok","timestamp":1746561448595,"user_tz":240,"elapsed":27343,"user":{"displayName":"Tanmay Bankar","userId":"15426054109741671763"}},"outputId":"1e1b6424-b570-4a56-df35-f7db9f788005"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","🦥 Unsloth Zoo will now patch everything to make training faster!\n","==((====))==  Unsloth 2025.4.7: Fast Llama patching. Transformers: 4.51.3.\n","   \\\\   /|    NVIDIA A100-SXM4-40GB. Num GPUs = 1. Max memory: 39.557 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.0. CUDA Toolkit: 12.4. Triton: 3.2.0\n","\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n"," \"-____-\"     Free license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"]}]},{"cell_type":"code","source":["model = FastLanguageModel.get_peft_model(\n","    model,\n","    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n","    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n","                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n","    lora_alpha = 16,\n","    lora_dropout = 0, # Supports any, but = 0 is optimized\n","    bias = \"none\",    # Supports any, but = \"none\" is optimized\n","    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n","    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n","    random_state = 3407,\n","    use_rslora = False,  # We support rank stabilized LoRA\n","    loftq_config = None, # And LoftQ\n",")"],"metadata":{"id":"l7TP-Je0hE7Z","executionInfo":{"status":"ok","timestamp":1746561454532,"user_tz":240,"elapsed":5938,"user":{"displayName":"Tanmay Bankar","userId":"15426054109741671763"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6beee05b-bec1-4827-9f4a-8eb4103c8c0f"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["Unsloth 2025.4.7 patched 16 layers with 16 QKV layers, 16 O layers and 16 MLP layers.\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lltZzYYqhWxe","executionInfo":{"status":"ok","timestamp":1746561455227,"user_tz":240,"elapsed":695,"user":{"displayName":"Tanmay Bankar","userId":"15426054109741671763"}},"outputId":"c0ff4e2b-b2d1-442b-c463-fcb5fe3eeca2"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["from datasets import load_dataset\n","txt_path = '/content/drive/MyDrive/HPML_Project/dataset/finance_corpus.txt'\n","\n","# one article per line in finance_corpus.txt (make sure you’ve uploaded it)\n","ds = load_dataset(\n","    \"text\",\n","    data_files={\"train\": txt_path},\n","    split=\"train\",\n",")\n","ds = ds.filter(lambda x: x[\"text\"].strip() != \"\")\n","\n","print(f\"Loaded {len(ds)} examples; sample text:\")\n","print(ds[0][\"text\"][:200].replace(\"\\n\",\" \"), \"…\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5_ALploEhXsp","executionInfo":{"status":"ok","timestamp":1746561455949,"user_tz":240,"elapsed":718,"user":{"displayName":"Tanmay Bankar","userId":"15426054109741671763"}},"outputId":"ddf9d546-ebcf-4f15-aea9-df23010a90b3"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded 227699 examples; sample text:\n","Article 1: Warren Buffett Autographed Books To Help Charity: Here's How You Can Get Legendary Investor's Signature …\n"]}]},{"cell_type":"code","source":["for text in ds[\"text\"][:10]:\n","    toks = tokenizer(text, add_special_tokens=False)\n","    print(len(toks[\"input_ids\"]), \"tokens\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K_9k-9GCKkvX","executionInfo":{"status":"ok","timestamp":1746561457114,"user_tz":240,"elapsed":1164,"user":{"displayName":"Tanmay Bankar","userId":"15426054109741671763"}},"outputId":"2d2da64d-94e1-4781-8bf3-f8f9d750347a"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["23 tokens\n","41 tokens\n","29 tokens\n","48 tokens\n","48 tokens\n","24 tokens\n","36 tokens\n","33 tokens\n","20 tokens\n","19 tokens\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"VtmreDNNJhA-","executionInfo":{"status":"ok","timestamp":1746561457121,"user_tz":240,"elapsed":6,"user":{"displayName":"Tanmay Bankar","userId":"15426054109741671763"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["from trl import SFTTrainer\n","from transformers import TrainingArguments, DataCollatorForSeq2Seq, DataCollatorForLanguageModeling\n","from unsloth import is_bfloat16_supported\n","\n","trainer = SFTTrainer(\n","    model = model,\n","    tokenizer = tokenizer,\n","    train_dataset = ds,\n","    dataset_text_field = \"text\",\n","    max_seq_length = max_seq_length,\n","    # data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer),\n","    data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False),\n","\n","    dataset_num_proc = 2,\n","    packing = False, # Can make training 5x faster for short sequences.\n","    args = TrainingArguments(\n","        per_device_train_batch_size = 64,\n","        gradient_accumulation_steps = 8,\n","        warmup_steps = 5,\n","        num_train_epochs = 5, # Set this for 1 full training run.\n","        # max_steps = 60,\n","        learning_rate = 1e-5,\n","        fp16 = not is_bfloat16_supported(),\n","        bf16 = is_bfloat16_supported(),\n","        logging_steps = 100,\n","        optim = \"adamw_8bit\",\n","        weight_decay = 0.01,\n","        lr_scheduler_type = \"linear\",\n","        seed = 3407,\n","        output_dir = \"outputs\",\n","        report_to = \"none\", # Use this for WandB etc\n","    ),\n",")"],"metadata":{"id":"vVo3DXWShZpk","executionInfo":{"status":"ok","timestamp":1746561479494,"user_tz":240,"elapsed":22372,"user":{"displayName":"Tanmay Bankar","userId":"15426054109741671763"}},"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["fcde6dbd522b4bcc8704e5728ff81522","cbe01edf4e1f429a9ebeade6f5ff4d95","20b14df9de3e48f0b299abb3be6b334b","a31e91c2910748cf83a935f81c63fd54","ea7340b323ae48f0b7ce2471844dce88","b9bf6fca43f2438195627702f8a22de6","49f45aedb1054b70b29ef4a0471ab1ab","01096f83b3dc4803b841987a16701fcf","d8022a63be6c4ab6a65b2d18dae3f284","12ee42d297604824aaccc6f1a38a082c","4e789055e9bb40f387668acd8348db06"]},"outputId":"e4fb1402-a6cb-4f86-daf8-47cc025b957e"},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":["Unsloth: Tokenizing [\"text\"] (num_proc=2):   0%|          | 0/227699 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fcde6dbd522b4bcc8704e5728ff81522"}},"metadata":{}}]},{"cell_type":"code","source":["tokenizer.decode(trainer.train_dataset[0][\"input_ids\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"baAtb0tawBMs","executionInfo":{"status":"ok","timestamp":1746561479502,"user_tz":240,"elapsed":3,"user":{"displayName":"Tanmay Bankar","userId":"15426054109741671763"}},"outputId":"671f6c1f-8a24-4ed8-9441-d8c96ae18a02"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"<|begin_of_text|>Article 1: Warren Buffett Autographed Books To Help Charity: Here's How You Can Get Legendary Investor's Signature\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["trainer.train_dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JS5u6_owwpnO","executionInfo":{"status":"ok","timestamp":1746561479509,"user_tz":240,"elapsed":7,"user":{"displayName":"Tanmay Bankar","userId":"15426054109741671763"}},"outputId":"f03e0998-bc9d-4e82-9117-3270dd940ff5"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['text', 'input_ids', 'attention_mask'],\n","    num_rows: 227699\n","})"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["trainer_stats = trainer.train()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":872},"id":"xWbhg-Vswn1C","outputId":"4439305e-cde8-4b5e-870a-9878b3c1ef1d","executionInfo":{"status":"ok","timestamp":1746565902830,"user_tz":240,"elapsed":4423320,"user":{"displayName":"Tanmay Bankar","userId":"15426054109741671763"}}},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n","   \\\\   /|    Num examples = 227,699 | Num Epochs = 5 | Total steps = 2,220\n","O^O/ \\_/ \\    Batch size per device = 64 | Gradient accumulation steps = 8\n","\\        /    Data Parallel GPUs = 1 | Total batch size (64 x 8 x 1) = 512\n"," \"-____-\"     Trainable parameters = 11,272,192/1,000,000,000 (1.13% trained)\n"]},{"output_type":"stream","name":"stdout","text":["Unsloth: Will smartly offload gradients to save VRAM!\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2220' max='2220' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2220/2220 1:13:36, Epoch 4/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>100</td>\n","      <td>3.128300</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>2.879600</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>2.774200</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>2.692900</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>2.668000</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>2.593800</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>2.560400</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>2.534800</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>2.535900</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>2.482800</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>2.479700</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>2.461800</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>2.443900</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>2.463300</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>2.430300</td>\n","    </tr>\n","    <tr>\n","      <td>1600</td>\n","      <td>2.418700</td>\n","    </tr>\n","    <tr>\n","      <td>1700</td>\n","      <td>2.406900</td>\n","    </tr>\n","    <tr>\n","      <td>1800</td>\n","      <td>2.424000</td>\n","    </tr>\n","    <tr>\n","      <td>1900</td>\n","      <td>2.398300</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>2.398400</td>\n","    </tr>\n","    <tr>\n","      <td>2100</td>\n","      <td>2.387800</td>\n","    </tr>\n","    <tr>\n","      <td>2200</td>\n","      <td>2.396800</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}}]},{"cell_type":"code","source":["FastLanguageModel.for_inference(model)\n","\n","def answer(prompt: str,\n","           max_new_tokens: int = 128,\n","           temperature: float    = 0.2,\n","           top_p: float          = 0.7,\n","           repetition_penalty: float = 1.2,\n","           no_repeat_ngram_size: int = 3):\n","    # 1) tokenize\n","    inputs = tokenizer(\n","        prompt,\n","        return_tensors=\"pt\",\n","        truncation=True,\n","        max_length=512\n","    ).to(model.device)\n","\n","    input_ids = inputs[\"input_ids\"]\n","\n","    # 2) generate with anti‐repetition tweaks\n","    outputs = model.generate(\n","        **inputs,\n","        max_new_tokens       = max_new_tokens,\n","        temperature          = temperature,\n","        top_p                = top_p,\n","        do_sample            = True,\n","        repetition_penalty   = repetition_penalty,\n","        no_repeat_ngram_size = no_repeat_ngram_size,\n","        eos_token_id         = tokenizer.eos_token_id,\n","        pad_token_id         = tokenizer.pad_token_id,\n","        early_stopping       = True,\n","    )\n","\n","    # 3) strip off prompt‐tokens and decode only the new ones\n","    gen_ids = outputs[0][ input_ids.shape[-1] : ]\n","    return tokenizer.decode(gen_ids, skip_special_tokens=True).strip()\n","\n","# Try it out\n","print(answer(\"How is starbucks doing?\"))"],"metadata":{"id":"NDoSjeazw_3c","executionInfo":{"status":"ok","timestamp":1746565907755,"user_tz":240,"elapsed":4921,"user":{"displayName":"Tanmay Bankar","userId":"15426054109741671763"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"abbe5a11-bfc7-4ac4-bc75-fcc0638cba4a"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["The company's stock has outperformed the Zacks Retail - Restaurants industry over the past year (+12.6% vs. +1%). This performance was driven by strong sales growth, which were fueled by a 7.9% increase in comparable store sales and an impressive 8.4% rise in total revenue. Starbucks' solid financials also helped it beat Wall Street estimates for both earnings per share (EPS) and revenues on two occasions during fiscal 2025. Its EPS of $2.74 surpassed analysts’ expectations by 10%. It delivered a significant improvement from its prior-year figure as well: EPS rose\n"]}]},{"cell_type":"code","source":["save_path = \"/content/drive/MyDrive/HPML_Project/unsloth_a100_2\"   # <— adjust if your folder is nested\n","\n","# 1) Save LoRA adapter + config\n","trainer.save_model(save_path)\n","\n","# 2) Save tokenizer files\n","tokenizer.save_pretrained(save_path)\n","\n","print(\" Saved adapters + tokenizer to\", save_path)"],"metadata":{"id":"4r2O9D3fxU-E","executionInfo":{"status":"ok","timestamp":1746565909472,"user_tz":240,"elapsed":1716,"user":{"displayName":"Tanmay Bankar","userId":"15426054109741671763"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b7e4339d-e133-4250-8d18-3b656bbc6ef6"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":[" Saved adapters + tokenizer to /content/drive/MyDrive/HPML_Project/unsloth_a100_2\n"]}]},{"cell_type":"markdown","source":["## Inference\n"],"metadata":{"id":"s23uOdZsCjLN"}},{"cell_type":"code","source":["# inference.py\n","\n","import torch\n","from peft import prepare_model_for_kbit_training, PeftModel\n","from unsloth import FastLanguageModel\n","\n","# 1) Load the same 4-bit base + tokenizer you fine-tuned on\n","base, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name     = \"unsloth/Llama-3.2-1B-bnb-4bit\",  # your base\n","    max_seq_length = 128,\n","    dtype          = torch.float16,                   # or None for auto\n","    load_in_4bit   = True,\n","    device_map     = \"auto\",\n",")\n","\n","# ensure pad/eos tokens are set\n","tokenizer.pad_token = tokenizer.eos_token\n","base.config.pad_token_id = tokenizer.pad_token_id\n","base.config.use_cache      = True\n","\n","# 2) Patch for QLoRA / k-bit adapters\n","base = prepare_model_for_kbit_training(base)\n","\n","# 3) Load your fine-tuned LoRA adapters\n","model = PeftModel.from_pretrained(\n","    base,\n","    \"/content/drive/MyDrive/HPML_Project/unsloth_a100_2\",     # folder where you saved adapters + tokenizer\n","    device_map=\"auto\",          # shard onto GPU automatically\n",")\n","\n","model.eval()\n","\n","# 4) Inference helper\n","def answer(prompt: str,\n","           max_new_tokens: int = 128,\n","           temperature: float    = 1.1,\n","           top_p: float          = 0.9,\n","           repetition_penalty: float = 1.2,\n","           no_repeat_ngram_size: int = 3):\n","    # 1) tokenize\n","    inputs = tokenizer(\n","        prompt,\n","        return_tensors=\"pt\",\n","        truncation=True,\n","        max_length=512\n","    ).to(model.device)\n","\n","    input_ids = inputs[\"input_ids\"]\n","\n","    # 2) generate with anti‐repetition tweaks\n","    outputs = model.generate(\n","        **inputs,\n","        max_new_tokens       = max_new_tokens,\n","        temperature          = temperature,\n","        top_p                = top_p,\n","        do_sample            = True,\n","        repetition_penalty   = repetition_penalty,\n","        no_repeat_ngram_size = no_repeat_ngram_size,\n","        eos_token_id         = tokenizer.eos_token_id,\n","        pad_token_id         = tokenizer.pad_token_id,\n","        early_stopping       = True,\n","    )\n","\n","    # 3) strip off prompt‐tokens and decode only the new ones\n","    gen_ids = outputs[0][ input_ids.shape[-1] : ]\n","    return tokenizer.decode(gen_ids, skip_special_tokens=True).strip()\n","\n","# Try it out\n","print(answer(\"How is starbucks stock doing?\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VH9QPCYFCiJv","executionInfo":{"status":"ok","timestamp":1746566388597,"user_tz":240,"elapsed":15409,"user":{"displayName":"Tanmay Bankar","userId":"15426054109741671763"}},"outputId":"fa5cfd5a-9ed6-41a1-b447-e042748fbd06"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["==((====))==  Unsloth 2025.4.7: Fast Llama patching. Transformers: 4.51.3.\n","   \\\\   /|    NVIDIA A100-SXM4-40GB. Num GPUs = 1. Max memory: 39.557 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.0. CUDA Toolkit: 12.4. Triton: 3.2.0\n","\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n"," \"-____-\"     Free license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","Starbucks (SBUX) beat revenue guidance in its Q1 2025 earnings call. It was a banner quarter, but it came with warning signs about future growth due to higher costs and competition from other food delivery companies such as DoorDash (DASH), Uber Eats (+18% year-over-year) and the major fast-food chains.(Read: Is Wall Street Overreacting To The Latest Starbucks Results?) How has analysts' price estimates for SBUX moved over time at Insider Monkey? Check our research report here on what they're worth! Stock Investor Report shows how this compares to rivals: StarbuckslimitsStarubucks\n"]}]},{"cell_type":"code","source":["# inference.py\n","\n","import torch\n","from peft import prepare_model_for_kbit_training, PeftModel\n","from unsloth import FastLanguageModel\n","\n","# 1) Load the same 4-bit base + tokenizer you fine-tuned on\n","base, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name     = \"unsloth/Llama-3.2-1B-bnb-4bit\",  # your base\n","    max_seq_length = 128,\n","    dtype          = torch.float16,                   # or None for auto\n","    load_in_4bit   = True,\n","    device_map     = \"auto\",\n",")\n","\n","# ensure pad/eos tokens are set\n","tokenizer.pad_token = tokenizer.eos_token\n","base.config.pad_token_id = tokenizer.pad_token_id\n","base.config.use_cache      = True\n","\n","# 2) Patch for QLoRA / k-bit adapters\n","base = prepare_model_for_kbit_training(base)\n","\n","# 3) Load your fine-tuned LoRA adapters\n","model = PeftModel.from_pretrained(\n","    base,\n","    \"/content/drive/MyDrive/HPML_Project/unsloth_a100_2\",     # folder where you saved adapters + tokenizer\n","    device_map=\"auto\",          # shard onto GPU automatically\n",")\n","\n","model.eval()\n","\n","# 4) Inference helper\n","def answer(prompt: str,\n","           max_new_tokens: int = 128,\n","           temperature: float    = 0.7,\n","           top_p: float          = 0.9,\n","           repetition_penalty: float = 1.2,\n","           no_repeat_ngram_size: int = 3):\n","    # 1) tokenize\n","    inputs = tokenizer(\n","        prompt,\n","        return_tensors=\"pt\",\n","        truncation=True,\n","        max_length=512\n","    ).to(model.device)\n","\n","    input_ids = inputs[\"input_ids\"]\n","\n","    # 2) generate with anti‐repetition tweaks\n","    outputs = model.generate(\n","        **inputs,\n","        max_new_tokens       = max_new_tokens,\n","        temperature          = temperature,\n","        top_p                = top_p,\n","        do_sample            = True,\n","        repetition_penalty   = repetition_penalty,\n","        no_repeat_ngram_size = no_repeat_ngram_size,\n","        eos_token_id         = tokenizer.eos_token_id,\n","        pad_token_id         = tokenizer.pad_token_id,\n","        early_stopping       = True,\n","    )\n","\n","    # 3) strip off prompt‐tokens and decode only the new ones\n","    gen_ids = outputs[0][ input_ids.shape[-1] : ]\n","    return tokenizer.decode(gen_ids, skip_special_tokens=True).strip()\n","\n","# Try it out\n","print(answer(\"What is the best performing stock?\"))"],"metadata":{"id":"djMnOyY1CyMv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1746566547226,"user_tz":240,"elapsed":15730,"user":{"displayName":"Tanmay Bankar","userId":"15426054109741671763"}},"outputId":"269de587-85ce-4d99-cf0e-530fe190c25e"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["==((====))==  Unsloth 2025.4.7: Fast Llama patching. Transformers: 4.51.3.\n","   \\\\   /|    NVIDIA A100-SXM4-40GB. Num GPUs = 1. Max memory: 39.557 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.0. CUDA Toolkit: 12.4. Triton: 3.2.0\n","\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n"," \"-____-\"     Free license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","Find out in our Top 5 Stocks for this week. Click to read now… Continue Reading about Best Performing Stock: Amphenol (APH) Upgraded To Outperform; Here’s What Analysts Say About It and Other Top Picks Now available on TipRanks.  was originally published by The Motley Fool, hereoriginally posted on March 13, 2025by The Motely Follownowavailable at https://www.themotleyfool.com/stocks/AAMPH-Stock-Tip-Rankings-Amphenol-AAPM-3Q25-Q1FY26-Earnings-Cost-and\n"]}]},{"cell_type":"code","source":["# inference.py\n","\n","import torch\n","from peft import prepare_model_for_kbit_training, PeftModel\n","from unsloth import FastLanguageModel\n","\n","# 1) Load the same 4-bit base + tokenizer you fine-tuned on\n","base, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name     = \"unsloth/Llama-3.2-1B-bnb-4bit\",  # your base\n","    max_seq_length = 128,\n","    dtype          = torch.float16,                   # or None for auto\n","    load_in_4bit   = True,\n","    device_map     = \"auto\",\n",")\n","\n","# ensure pad/eos tokens are set\n","tokenizer.pad_token = tokenizer.eos_token\n","base.config.pad_token_id = tokenizer.pad_token_id\n","base.config.use_cache      = True\n","\n","# 2) Patch for QLoRA / k-bit adapters\n","base = prepare_model_for_kbit_training(base)\n","\n","# 3) Load your fine-tuned LoRA adapters\n","model = PeftModel.from_pretrained(\n","    base,\n","    \"/content/drive/MyDrive/HPML_Project/unsloth_a100_2\",     # folder where you saved adapters + tokenizer\n","    device_map=\"auto\",          # shard onto GPU automatically\n",")\n","\n","model.eval()\n","\n","# 4) Inference helper\n","def answer(prompt: str,\n","           max_new_tokens: int = 128,\n","           temperature: float    = 1,\n","           top_p: float          = 0.9,\n","           repetition_penalty: float = 1.2,\n","           no_repeat_ngram_size: int = 3):\n","    # 1) tokenize\n","    inputs = tokenizer(\n","        prompt,\n","        return_tensors=\"pt\",\n","        truncation=True,\n","        max_length=512\n","    ).to(model.device)\n","\n","    input_ids = inputs[\"input_ids\"]\n","\n","    # 2) generate with anti‐repetition tweaks\n","    outputs = model.generate(\n","        **inputs,\n","        max_new_tokens       = max_new_tokens,\n","        temperature          = temperature,\n","        top_p                = top_p,\n","        do_sample            = True,\n","        repetition_penalty   = repetition_penalty,\n","        no_repeat_ngram_size = no_repeat_ngram_size,\n","        eos_token_id         = tokenizer.eos_token_id,\n","        pad_token_id         = tokenizer.pad_token_id,\n","        early_stopping       = True,\n","    )\n","\n","    # 3) strip off prompt‐tokens and decode only the new ones\n","    gen_ids = outputs[0][ input_ids.shape[-1] : ]\n","    return tokenizer.decode(gen_ids, skip_special_tokens=True).strip()\n","\n","# Try it out\n","print(answer(\"What is the news on Lockheed Martin?\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FE_anQYVdGfv","executionInfo":{"status":"ok","timestamp":1746566737300,"user_tz":240,"elapsed":15297,"user":{"displayName":"Tanmay Bankar","userId":"15426054109741671763"}},"outputId":"b19b08a8-60b1-410a-9d1a-41928b0c260a"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["==((====))==  Unsloth 2025.4.7: Fast Llama patching. Transformers: 4.51.3.\n","   \\\\   /|    NVIDIA A100-SXM4-40GB. Num GPUs = 1. Max memory: 39.557 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.0. CUDA Toolkit: 12.4. Triton: 3.2.0\n","\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n"," \"-____-\"     Free license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","2.30% (0%) Upward revision of Earnings Per Share Estimates from $6.88 to $7, and a 5-Year EPS Growth Rate Estimate for 23%, up by approximately +8%. What should we expect from this earnings announcement in terms of business outlooks or expectations about growth opportunities around aerospace defense, commercial air transport and space programs as well as new strategic initiatives that may arise with geopolitical events such as tariffs? Do you anticipate any specific challenges related to trade-related risks within your supply chains impacting these sectors? Are there underlying structural changes in demand expected that could affect end markets, including travel & tourism following\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"TKTjvdjwezAA"},"execution_count":null,"outputs":[]}]}